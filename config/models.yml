- title: ChatGLM-中英对话大模型-6B-Int4
  author: 智谱.AI
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/ChatGLM-6B-Int4.tar.gz
  tags: PyTorch,文本生成
  license: Apache License 2.0
  desc: ChatGLM-6B 是一个开源的、支持中英双语问答的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。ChatGLM-6B 使用了和 ChatGLM 相同的技术，针对中文问答和对话进行了优化。ChatGLM-6B-INT4 是 ChatGLM-6B 量化后的模型权重。具体的，ChatGLM-6B-INT4 对 ChatGLM-6B 中的 28 个 GLM Block 进行了 INT4 量化，没有对 Embedding 和 LM Head 进行量化。量化后的模型理论上 6G 显存（使用 CPU 即内存）即可推理，具有在嵌入式设备（如树莓派）上运行的可能。
- title: 百川2-7B-对话模型-4bits量化版
  author: 百川智能
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/Baichuan2-7B-Chat-4bits.tar.gz
  tags: PyTorch,文本生成
  license: 其它
  desc: Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。Baichuan 2 在多个权威的中文、英文和多语言的通用、领域 benchmark 上取得同尺寸最佳的效果。本次发布包含有 7B、13B 的 Base 和 Chat 版本，并提供了 Chat 版本的 4bits 量化。所有版本对学术研究完全开放。同时，开发者通过邮件申请并获得官方商用许可后，即可免费商用。
- title: 书生·浦语-对话-7B-v1_1
  author: 上海人工智能实验室
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/internlm-chat-7b-v1_1.tar.gz
  tags: PyTorch,文本生成
  license: Apache License 2.0
  desc: 书生·浦语大模型，包含面向实用场景的70亿参数基础模型与对话模型 （InternLM-7B）。模型具有以下特点：使用上万亿高质量预料，建立模型超强知识体系；支持8k语境窗口长度，实现更长输入与更强推理体验；通用工具调用能力，支持用户灵活自助搭建流程；模型权重对学术研究完全开放，也可申请免费的商业使用授权。
- title: 通义千问-7B-Chat-Int4
  author: 通义千问
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/Qwen-7B-Chat-Int4.tar.gz
  tags: PyTorch,Safetensors,文本生成
  license: 其它
  desc: 通义千问是阿里云研发的的70亿参数规模的大模型。Qwen-7B是基于Transformer的大语言模型, 在超大规模的预训练数据上进行训练得到。预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。同时，在Qwen-7B的基础上，我们使用对齐机制打造了基于大语言模型的AI助手Qwen-7B-Chat。相较于最初开源的Qwen-7B模型，我们现已将预训练模型和Chat模型更新到效果更优的版本。本模型为Qwen-7B-Chat的Int4量化模型。代码和模型权重对学术研究完全开放，并支持商用。请查看LICENSE了解具体的开源协议细节。
- title: Llama-2-7b-ms
  author: ModelScope
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/Llama-2-7b-ms.tar.gz
  tags: PyTorch,Safetensors,文本生成
  license: 其它
  desc: 自Meta开发并公开发布的，LLaMa 2系列的大型语言模型，本模型为7B规模的预训练版本，并适配到ModelScope生态，可以通过ModelScope library加载。使用此模型受Meta许可证的约束。为了下载模型权重和分词器，请访问网站并在此处请求访问前接受我们的许可证。
- title: 太乙-Stable-Diffusion-1B-中文
  author: 封神榜
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/Taiyi-Stable-Diffusion-1B-Chinese-v0.1.tar.gz
  tags: 文生图
  license: creativeml-openrail-m
  desc: 首个开源的中文Stable Diffusion模型，基于0.2亿筛选过的中文图文对训练而成
- title: 姜子牙-LLaMA-13B-v1.1
  author: 封神榜
  download_url: https://opencsg-model-dataset.oss-cn-beijing.aliyuncs.com/models/Ziya-LLaMA-13B-v1.1.tar.gz
  tags: PyTorch,文本生成
  license: GPL-3.0
  desc: 通用大模型“姜子牙”系列，具备翻译，编程，文本分类，信息抽取，摘要，文案生成，常识问答和数学计算等能力，通过调整微调数据的比例和采用更优的强化学习策略，本版本在问答准确性、数学能力以及安全性等方面得到了提升


